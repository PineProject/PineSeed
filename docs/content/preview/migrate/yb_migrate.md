---
title: Database Migration Service
headerTitle: Database Migration Service
linkTitle: Database Migration Service
description: Overview of the yb_migrate database engine for migrating data and applications from other databases to YugabyteDB.
beta: /preview/faq/general/#what-is-the-definition-of-the-beta-feature-tag
menu:
  preview:
    identifier: yb-migrate
    parent: migrate
    weight: 720
isTocNested: true
showAsideToc: true
---

[yb_migrate](https://github.com/yugabyte/yb-db-migration) is an open-source database migration engine provided by YugabyteDB. It is a command line executable program that supports migrating databases from PostgreSQL, Oracle, and MySQL to a YugabyteDB database. yb_migrate helps in both steps of a database migration - schema-migration and data-migration.

{{< note title="Note" >}}

yb_migrate supports `offline` migration mode. The `online` migration mode is currently under development.

{{< /note >}}

- In the *offline migration* mode, the source database must not change during the migration. The offline migration is considered done when all the requested schema objects and data is migrated to the target database.

- In the *online migration* mode, the source database can continue to change. After the full initial migration, yb_migrate continues replicating source database changes to the target database. The process runs continuously, until you decide to switch-over to the YugabyteDB database.

A typical migration workflow using yb_migrate consists of following steps:

- Install yb_migrate on a "migrator machine".
- Use the `yb_migrate export schema` command to convert Source Database schema to Postgres format.
- Use the `yb_migrate analyze-schema` command to generate a Schema Analysis Report. The report suggests changes to the PostgreSQL schema to make it appropriate for YugabyteDB.
- Manually change the exported schema as suggested in the Schema Analysis Report.
- Use the `yb_migrate export data` command to dump the Source Database in the local files on the migrator machine.
- Use the `yb_migrate import schema` command to import the schema in the target YugabyteDB database.
- Use the `yb_migrate import data` command to import the data in the target YugabyteDB database.

## How does yb_migrate work?

[Diagram]

yb_migrate is installed on and performs a migration from a "migrator machine". A migrator machine must meet following requirements:
- Runs CentOS or Ubuntu.
- Can reach both source and target DB.
- Has local storage of at least 1.5 times the size of source DB.

yb_migrate keeps all of its migration state, including exported schema and data, in a local directory called "export directory". Before starting migration, you must create the directory on a file-system that has enough space to keep the entire data dump. Then you must provide the path of the export directory as a mandatory argument (`--export-dir`) to each invocation of the yb_migrate command.

The export directory has following sub-directories/files:
- `reports/` directory contains the generated Migration Assessment Report.
- `schema/` directory contains source DB schema translated to PostgreSQL. The schema is partitioned into smaller files by the schema object type e.g. tables, views, etc.
- `data/` directory contains TSV (Tab Separated Values) files that are passed to the COPY command on the target DB.
- `metainfo/` and `temp/` directories are used by yb_migrate for internal bookkeeping.
- `yb_migrate.log` contains log messages.

In the export phase, yb_migrate uses `ora2pg` (for Oracle and MySQL) or `pg_dump` (for PostgreSQL) to dump schema and data in the PostgreSQL format.

Given that YugabyteDB is a distributed database and uses storage format different from PostgreSQL, minor manual changes are required to the PostgreSQL schema dumped by the yb_migrate. The report generated by the `yb_migrate analyze-schema` command, points at the various schema files that you should manually change before trying to import the schema.

In the import schema phase, yb_migrate simply applies the DDL SQL files (located in the `$EXPORT_DIR/schema` directory) to the target DB.

In the import data phase, yb_migrate splits the data dump files (from the `$EXPORT_DIR/data` directory) into smaller "batches"--each of which contains at most `--batch-size` number of records. yb_migrate concurrently ingests the batches such that all nodes of the target YugabyteDB cluster are utilized. The import data phase is designed to be "restartable"--if yb_migrate terminates when the data import was in progress, upon restart the data import resumes where it left off in the previous run.

## Limitations

- yb_migrate doesn't yet support following features:

  - BLOB and CLOB
  - TABLESPACEs
  - ALTER VIEW


## Installation

### Machine requirements
The machine where you will run the yb_migrate command must satisfy following requirements:
- Runs CentOS or Ubuntu.
- Can reach both source and target DB.
- Has local storage at least 1.5 times the size of source DB.
- You must have sudo access to the machine.

Follow the steps given below, to setup a machine where you can run yb_migrate:

- Open a terminal session to the migrator machine.

- Clone the yb_migrate git repository:

        git clone https://github.com/yugabyte/yb-db-migration.git

- Change the directory to `yb-db-migration/installer_scripts`:

        cd yb-db-migration/installer_scripts

- Depending on the Linux distribution you're running, execute the appropriate installer script:

        ./yb_migrate_installer__centos.sh
    or

        ./yb_migrate_installer__ubuntu.sh

  The scripts are interactive--they can ask `Y` or `N` responses.

  It is safe to execute the script multiple times. On each run, the script regenerates the `yb_migrate` executable based on the latest commit in the git repository.

   If the script fails for some reason, check the `yb_migrate_installer.log` in the current working directory.

- The script generates a `.yb_migrate_installer_bashrc` file in the home directory. Make sure to source the file so that correct environment variables are set:

        source ~/.yb_migrate_installer_bashrc

- Run `yb_migrate --help` to check whether you have a working yb_migrate installation.

---
# Database Migration Process

Migrating a database from the source database to the target database requires the following steps:
- Prepare the source database.
- Prepare the target database.
- Export schema.
- Generate Schema Analysis Report.
- Manually edit the schema.
- Regenerate the Schema Analysis Report. Continue doing manual changes until the report contains zero issues.
- Export data.
- Import schema.
- Import data.
- Verify target database.

Following sections provide details of each of the above steps.

## Prepare the Source database

Create a new database user and provide it with READ access to all the resources which need to be migrated.

### PostgreSQL

Note that currently `yb_migrate` only supports migrating ALL schemas of the source DB. It does not support migrating only a subset of the schemas. This limitation will be addressed in the near future.

Run the following list of commands in a `psql` session:

- Create a new user named `ybmigrate`:

      CREATE USER ybmigrate PASSWORD 'password';

- Switch to the database that you want to migrate.

      \c <database_name>

- Grant the `USAGE` permission to the `ybmigrate` user on all schemas of the database:

      SELECT 'GRANT USAGE ON SCHEMA ' || schema_name || ' TO ybmigrate;' FROM information_schema.schemata; \gexec

  The above `SELECT` statement generates a list of `GRANT USAGE` statements which are then executed by `psql` because of the `\gexec` switch.

- Similarly, grant `SELECT` permission on all tables and sequences:

      SELECT 'GRANT SELECT ON ALL TABLES IN SCHEMA ' || schema_name || ' TO ybmigrate;' FROM information_schema.schemata; \gexec

      SELECT 'GRANT SELECT ON ALL SEQUENCES IN SCHEMA ' || schema_name || ' TO ybmigrate;' FROM information_schema.schemata; \gexec

- Now, you can use the `ybmigrate` user for the migration.

### MySQL

Replace the `'localhost'` from the following commands with an appropriate host-name in your setup.

- Create a new user `ybmigrate`:

      CREATE USER 'ybmigrate'@'localhost' IDENTIFIED WITH  mysql_native_password BY 'Password#123';

- Grant the global `PROCESS` permission:

      GRANT PROCESS ON *.* TO 'ybmigrate'@'localhost';

- Grant the `SELECT`, `SHOW VIEW`, and `TRIGGER` permissions on the source database:

      GRANT SELECT ON source_db_name.* TO 'ybmigrate'@'localhost';
      GRANT SHOW VIEW ON source_db_name.* TO 'ybmigrate'@'localhost';
      GRANT TRIGGER ON source_db_name.* TO 'ybmigrate'@'localhost';

- If you are running MySQL version >= 8.0.20, grant the global `SHOW_ROUTINE` permission. For older versions, grant the global `SELECT` permission. These permissions are necessary to dump stored procedure/functions definitions:

      -- For MySQL >= 8.0.20
      GRANT SHOW_ROUTINE  ON *.* TO 'ybmigrate'@'localhost';

      -- For older MySQL
      GRANT SELECT ON *.* TO 'ybmigrate'@'localhost';

- Now, you can use the `ybmigrate` user for the migration.

### Oracle

- Create a role that has following privileges:

  -- `SELECT` permission is required on all VIEW, SEQUENCE, TABLE PARTITION,
     TABLE, SYNONYM, MATERIALIZED VIEW in the source schema.

  -- `EXECUTE` permission on all PROCEDURE, FUNCTION, PACKAGE, PACKAGE BODY, TYPE
      in the source schema.

      -- Change the <SCHEMA_NAME> appropriately in the following snippets.
      -- Run the following steps with a privileged user.
      CREATE ROLE schema_ro_role;

      BEGIN
        FOR R IN (SELECT owner, object_name FROM all_objects WHERE owner='<SCHEMA_NAME>' and object_type in ('VIEW','SEQUENCE','TABLE PARTITION','TABLE','SYNONYM','MATERIALIZED VIEW')) LOOP
            EXECUTE IMMEDIATE 'grant select on '||R.owner||'."'||R.object_name||'" to schema_ro_role';
        END LOOP;
      END;
      /

      BEGIN
        FOR R IN (SELECT owner, object_name FROM all_objects WHERE owner='<SCHEMA_NAME>' and object_type in ('PROCEDURE','FUNCTION','PACKAGE','PACKAGE BODY', 'TYPE')) LOOP
            EXECUTE IMMEDIATE 'grant execute on '||R.owner||'."'||R.object_name||'" to schema_ro_role';
        END LOOP;
      END;
      /

- Create a user `ybmigrate` and grant `CONNECT` and `schema_ro_role` to the user:

      CREATE USER ybmigrate IDENTIFIED BY password;
      GRANT CONNECT TO ybmigrate;
      GRANT schema_ro_role TO ybmigrate;

- Create a trigger to set change current schema whenever the `ybmigrate` user connects:

      CREATE OR REPLACE TRIGGER ybmigrate.after_logon_trg
      AFTER LOGON ON ybmigrate.SCHEMA
      BEGIN
          DBMS_APPLICATION_INFO.set_module(USER, 'Initialized');
          EXECUTE IMMEDIATE 'ALTER SESSION SET current_schema=<SCHEMA_NAME>';
      END;
      /

- The `ybmigrate` user can now be used for migration.


You will need to provide the user and the source database details in the subsequent invocations of yb_migrate. For convenience, you can populate the information in the following environment variables:

        SOURCE_DB_TYPE=oracle
        SOURCE_DB_HOST=localhost
        SOURCE_DB_PORT=1521
        SOURCE_DB_USER=ybmigrate
        SOURCE_DB_PASSWORD=password
        SOURCE_DB_NAME=pdb1
        SOURCE_DB_SCHEMA=sakila

Replace values of the above environment variables as per your database details.

SOURCE_DB_TYPE can be one of [`postgresql`, `mysql`, `oracle`].

If you want yb_migrate to connect to the source database over SSL, refer to [SSL Connectivity](#ssl-connectivity) in the References section.

## Prepare the target database

### Create the target database

Create the target database in the YugabyteDB cluster. The database name can be the same or different from the source database name. If you choose the target database name different from the source database name, you will have to provide the `--target-db-name` argument to the `yb_migrate import` commands.

      CREATE DATABASE sakila;

For convenience, capture the database name in an environment variable:

      TARGET_DB_NAME=sakila


### Create a user

User creation steps slightly differ depending on the YugabyteDB deployment and version:

- **YugabyteDB Managed or YugabyteDB Anywhere version >= 2.13.1, 2.12.4**

  Create a user with `yb_db_admin` and `yb_superuser` role:

      CREATE USER ybmigrate PASSWORD 'password';
      GRANT yb_db_admin TO ybmigrate;
      GRANT yb_superuser TO ybmigrate;

- **YugabyteDB Anywhere version < 2.13.1, 2.12.4**

  Create a role with the superuser privileges.

      CREATE USER ybmigrate SUPERUSER PASSWORD 'password';

Capture the user and database details in environment variables.

        TARGET_DB_HOST=127.0.0.1
        TARGET_DB_PORT=5433
        TARGET_DB_USER=ybmigrate
        TARGET_DB_PASSWORD=password

If you want yb_migrate to connect to the target database over SSL, refer to [SSL Connectivity](#ssl-connectivity) in the References section.

Be careful while deleting the `ybmigrate` user after completion of the migration. After migration, all the migrated objects (tables, views, etc.) are owned by the `ybmigrate` user. You must transfer the ownership of the objects to some other user (e.g. `yugabyte`) before deleting the it. Example steps to delete the user are:

    REASSIGN OWNED BY ybmigrate TO yugabyte;
    DROP OWNED BY ybmigrate;
    DROP USER ybmigrate;

## Create an export directory

Before you proceed with the actual migration steps, create an "export directory" in the local file-system on the migrator machine. yb_migrate uses the directory to store source data, schema files, and migration state. The file-system in which the directory resides must have enough free space to hold the entire source database. Create the directory and place its path in an environment variable.

        mkdir -p ~/export-dirs/sakila
        EXPORT_DIR=~/export-dirs/sakila

## Export schema

`yb_migrate export schema` command extracts the schema from the source database; converts it into PostgreSQL format (if the source database is Oracle or MySQL); and dumps the SQL DDL files in the `EXPORT_DIR/schema/*` directories.

An example invocation of the command looks like:

        yb_migrate export schema --export-dir ${EXPORT_DIR} \
            --source-db-type ${SOURCE_DB_TYPE} \
            --source-db-host ${SOURCE_DB_HOST} \
            --source-db-user ${SOURCE_DB_USER} \
            --source-db-password ${SOURCE_DB_PASSWORD} \
            --source-db-name ${SOURCE_DB_NAME} \
            --source-db-schema ${SOURCE_DB_SCHEMA}

## Analyze Schema

Using `ora2pg` and `pg_dump`, yb_migrate can easily extract and convert the source database schema to an equivalent PostgreSQL schema. But the schema may not be suitable, yet, to be imported into the YugabyteDB. Even though YugabyteDB is PostgreSQL compatible, given its distributed nature, you may need some minor changes to the schema. Refer [this document](#https://docs.google.com/document/d/1jCLiHDEHiYpgVObILDC_2Ormr-Kx36YhkqHXUCVGO1Q/edit#) to know more about modeling data for YugabyteDB.

The `yb_migrate analyze-schema` command analyses the PostgreSQL schema dumped in the previous step and prepares a report that lists the DDL statements that need changes. Here is a sample invocation of the command:

        yb_migrate analyze-schema --export-dir ${EXPORT_DIR} \
            --source-db-type ${SOURCE_DB_TYPE} \
            --source-db-host ${SOURCE_DB_HOST} \
            --source-db-user ${SOURCE_DB_USER} \
            --source-db-password ${SOURCE_DB_PASSWORD} \
            --source-db-name ${SOURCE_DB_NAME} \
            --source-db-schema ${SOURCE_DB_SCHEMA} \
            --output-format txt

The `--output-format` can be one of the `html`, `txt`, `json`, and `xml`.

The above command generates a report file in the `EXPORT_DIR/reports/`.

## Manually edit the schema

Fix all the issues, listed in the generated schema analysis report, by manually editing the SQL DDL files from the `EXPORT_DIR/schema/*`. In future, yb_migrate will take over some of these manual schema changes.

After making the changes, rerun the same `yb_migrate analyze-schema` command. The command will generate a fresh report taking into account your changes. Repeat these steps until the generated report contains no issues.

## Export data

Run the `yb_migrate export data` command to dump the source data into the `EXPORT_DIR/data` directory. For example,

        yb_migrate export data --export-dir ${EXPORT_DIR} \
            --source-db-type ${SOURCE_DB_TYPE} \
            --source-db-host ${SOURCE_DB_HOST} \
            --source-db-user ${SOURCE_DB_USER} \
            --source-db-password ${SOURCE_DB_PASSWORD} \
            --source-db-name ${SOURCE_DB_NAME} \
            --source-db-schema ${SOURCE_DB_SCHEMA}

The options passed to the command are similar to the `export schema` command.

To export only a subset of the tables, pass a comma separated list of table names in the `--table-list` argument.

To speed up the data export of larger source databases, you can pass values greater than 1 to the `--parallel-jobs` argument. It will cause yb_migrate to dump multiple tables concurrently.

## Import schema

Once you're done with manually editing the schema, you can use the `yb_migrate import schema` command to import the schema. For example,

        yb_migrate import schema --export-dir ${EXPORT_DIR} \
            --target-db-host ${TARGET_DB_HOST} \
            --target-db-port ${TARGET_DB_PORT} \
            --target-db-user ${TARGET_DB_USER} \
            --target-db-password ${TARGET_DB_PASSWORD:-''} \
            --target-db-name ${TARGET_DB_NAME}

For Oracle and MySQL, `yb_migrate` imports the source database into the `public` schema of the target database. By specifying `--target-db-schema` argument during import, you can instruct `yb_migrate` to create a non-public schema and use it for the schema/data import.

For PostgreSQL, there is no need to provide the target db schema name. For each schema in source PG database, yb_migrate creates a target schema with the same name.

If for some reason, yb_migrate terminates before it could import the entire schema, you can rerun it by adding `--ignore-exist` option.

Note that, the `yb_migrate import schema` command does NOT import indexes, yet. This is done to speed up the data import phase. The indexes will be created by `yb_migrate import data` command after importing the data.

## Import data

After you have successfully exported the source data and imported the schema in the target database, you can now import the data using the `yb_migrate import data` command:

        yb_migrate import data --export-dir ${EXPORT_DIR} \
            --target-db-host ${TARGET_DB_HOST} \
            --target-db-port ${TARGET_DB_PORT} \
            --target-db-user ${TARGET_DB_USER} \
            --target-db-password ${TARGET_DB_PASSWORD:-''} \
            --target-db-name ${TARGET_DB_NAME}

The `yb_migrate import data` command reads data files located in the `EXPORT_DIR/data`.

The command, by default, creates one database connection to each of the nodes of the target YugabyteDB cluster. You can increase the number of connections by specifying the total connection count in the `--parallel-jobs` argument. The command will equally distribute the connections among all the nodes of the cluster.

The command splits the larger tables into smaller chunks--each containing at most `--batch-size` number of records. By default, the `--batch-size` is 100,000 records.

To get the overall progress of the data import operation, run the `yb_migrate import data status --export-dir ${EXPORT_DIR}` command in a different terminal window.

While importing a very large database, you should run the import data command in a `screen` session, so that the import is not terminated when the terminal session stops.

If the `yb_migrate import data` command terminates before it could complete the data ingestion, you can rerun it with the same arguments and the command will resume the data import from where it left off.

After successfully loading the data, the command creates the indexes listed in the schema.

## Verify target database

After the successful execution of the `yb_migrate import data` command, the automated part of the database migration process is considered as done. You should manually run validation queries on both source and target database to ensure that the data is correctly migrated. The validation queries can be as simple as checking the row count in each table or it can utilise some domain knowledge e.g. match the sum of the `amount` column in the `payments` table.

---

# References

## SSL Connectivity

You can instruct yb_migrate to connect to the source/target database over an SSL connection.

Connecting securely to any of the PostgreSQL, MySQL, and YugabyteDB requires you to pass a very similar set of arguments to the yb_migrate. For Oracle, on the other hand, requires a different set of arguments.

### PostgreSQL and MySQL

- `--source-ssl-mode (disable|allow|prefer|require|verify-ca|verify-full)`
    Value of this argument determines:
    - whether an encrypted connection is established between yb_migrate and the database server; and
    - whether the certificate of the database server is verified from a CA.

    Possible values and their meaning is given below:
    - `disable`: Only try a non-SSL connection.
    - `allow`: First try a non-SSL connection; if that fails, try an SSL connection. (Not supported for MySQL.)
    - `prefer` (default): First try an SSL connection; if that fails, try a non-SSL connection.
    - `require`: Only try an SSL connection. If a root CA file is present, verify the certificate in the same way as if verify-ca was specified.
    - `verify-ca`: Only try an SSL connection, and verify that the server certificate is issued by a trusted certificate authority (CA).
    - `verify-full`: Only try an SSL connection, verify that the server certificate is issued by a trusted CA and that the requested server host name matches that in the certificate.

- `--source-ssl-cert` and `--source-ssl-key`

    These two arguments specify names of the files containing SSL certificate and key, respectively. The <cert, key> pair forms the identity of the client.

- `--source-ssl-root-cert`

    This parameter specifies the path to a file containing SSL certificate authority (CA) certificate(s). If the file exists, the server's certificate will be verified to be signed by one of these authorities.

- `--source-ssl-crl`

    This parameter specifies the path to a file containing the SSL certificate revocation list (CRL). Certificates listed in this file, if it exists, will be rejected while attempting to authenticate the server's certificate.

### YugabyteDB

You need to pass following arguments to yb_migrate to establish an SSL connection with YugabyteDB:
- `--target-ssl-mode`
- `--target-ssl-cert`
- `--target-ssl-key`
- `--target-ssl-root-cert`
- `--target-ssl-crl`

Semantics of these arguments match with the similarly named arguments described in the previous section.

### Oracle

For Oracle, create a TNS alias that is configured to establish a secure connection with the server. You must then pass the TNS alias to yb_migrate as `--oracle-tns-alias` argument. yb_migrate uses the TNS alias to securely connect to the server.

When you pass the `--oracle-tns-alias` argument, you don't need to pass the `--source-db-host`, `--source-db-port`, and `--source-db-name` arguments to the yb_migrate.

## Manual Schema Changes

Some examples of manual schema changes:

- **`CREATE INDEX CONCURRENTLY` NOT SUPPORTED**:

  This feature is not supported yet in YugabyteDB. You should remove the `CONCURRENTLY` clause before trying to import the schema.

- **Primary Key cannot be added to Partitioned table using ALTER TABLE**:

  Add the primary key definition right in the `CREATE TABLE` statement itself.
